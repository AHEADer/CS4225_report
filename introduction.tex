\documentclass[base.tex]{subfiles}
\begin{document}
\section{Project Introduction}
With big data explosion and the rise of Internet-of-Things during recent years, efficiently processing geographically distributed data is becoming increasingly important. Large scale corporations are deploying datacenters and clusters globally on the ``edge'' to provide their users low latency access to their services. \iffalse Often these corporations employ the services of well established and geographically distributed commercial cloud providers to implement geo-distributed data analytics services. \fi For instance, Microsoft and Google have scores of datacenters (DCs)~\cite{googledata2018,microsoftdata2018} providing services to various organizations. The services deployed on these geo-distributed sites generate a large amount of data continuously, such as, user activity, session logs, server monitoring logs, and performance counters among others. In addition, there are some geo-distributed applications that  process and analyze this large volume of geo-distributed data to obtain the final result. Because these analytics jobs usually support the real-time decisions and on-line predictions, minimizing response time are essential. However, these face the unique challenges of wide area network (WAN) bandwidth limits, legislative and regulatory constraints, unreliable runtime environment, and even monetary costs.

Distributed data processing is a well-studied topic in computer science. The development of distributed processing frameworks, such as Hadoop and Spark, have led to scalable, fault tolerant and efficient real-time and batch data processing. However, all these popular systems have a major drawback in terms of locally distributed computations. When input data is located across multiple datacenters, conventional approach is to aggregate all the data to a single datacenter before processing. Naturally, transferring huge amounts of data across datacenters may result in substantial network traffic and increase job completion time.

The natural alternative to this approach is to leave data in-place and use unmodified, intra-DC analytics framework (such as Hadoop or Spark) across the collection of sites. However, such distributed frameworks are designed for non-geo-distributed clusters, thus lack consideration to some of the major characteristics in geo-distributed clusters and job execution could be dramatically inefficient. For instance, in a local cluster, the intra node network is often homogeneous and with very high consistent bandwidth, while geo-distributed clusters have heterogeneous network links connecting nodes with fluctuating network bandwidths. Therefore, state-of-the-art distributed processing frameworks need to be extended for geo-distributed data clusters, while giving due concern for new challenges in the geo-distributed network and data.
   
%Geo-distributed databases and systems have been in existence for a long time~\cite{jayalath2014cloud}. However, there are some shortcomings about Geo-distributed databases and systems. For instance, these systems are not practically flexible, highly fault-tolerant, very scalable, able to process large scale (and/or real-time) data, good enough for massively parallel processing, fast in answering a query, and simple to program. 
%The method about transferring all the data to be manipulated to a single datacenter is widely-used. In this way, these data can be processed in a centralized fashion. Nevertheless, to some degree, such traditional approach may not have feasible performance in practice at times. There are several reasons about this case. 
%Therefore, the natural alternative method to this approach is to execute the queries geo-distributedly over the massive data stored at the sites. State-of-the-art big-data processing frameworks such as MapReduce, Hadoop and Spark have been designed to overcome the disadvantages (e.g., fault-tolerance, unstructured/massive data processing, or slow processing time) of parallel computing, distributed databases, and cluster computing. However, these processing frameworks do not consider the network when they do task placement, which is a main drawback as the geo-distributed sites are connected via wide area network (WAN) links with heterogeneous and modest bandwidths, unlike intra-datacenter networks.

One of the major challenges in geo-distributed processing systems is determining the task placement among many sites. There are existing research that have attempted different heuristic based optimization approaches to improve task placement. However, they lack concern to the heterogeneous nature of the network connecting the sites, do not consider applications with complex data flow having multiple execution stages, of take too long to get the task placement due to compute expensive optimization algorithm making them less applicable in realistic geo-distributed processing systems. 

Given an application with jobs having multiple execution stages represented by a Directed Acyclic Graph (DAG), We develop an analytical modeling approach to determine the total completion time for a single job on a geo-distributed cluster. We assume that the data is initially non-evenly distributed across the geo-distributed sites and the network connecting these sites have heterogeneous links with different link bandwidths. Take Apache Spark as an example, We validate our model on a geo-distributed Spark cluster spanning multiple Amazon AWS cloud regions. Using our model, We present useful insights into the impact of different aspects in geo-distributed data processing on job execution time.

\subsection{Related Work}
\iffalse
Previously, the amount of data is limited, KB, MB are the units always seen when describing the amount. However, innovation of data storing technique and frequent worldwide communication promote data sharing. Thus, not only the amount of data, but also the co-operate of processing massive data is gaining its attention. 
\fi
With increasingly large volumes of data generated globally and stored in geo-distributed datacenters, people are performing an increasing amount of research attention to processing data throughout multiple datacenters. The main ideas are similar: making query execution (specifically, data and task placement) WAN-aware. Based on their objectives, existing efforts can be roughly divided into two categories: reducing the amount of inter-datacenter network traffic to save operation costs and reducing the job completion time to improve application performance.

Reducing the amount of traffic among different datacenters is proposed in \cite{vulimiri2015global, kloudas2015pixida}. In\cite{vulimiri2015global}, they design an integer programming problem for optimizing the query execution plan and the data replication strategy to reduce the bandwidth costs. As they assume each datacenter has limitless storage, they aggressively cache the results of prior queries to reduce the data transfers of subsequent queries. In Pixida~\cite{kloudas2015pixida}, they propose a new way to aggregate the tasks in the original Directed Acyclic Graph to make the Directed Acyclic Graph simpler. After that, they propose a new generalized min-k-cut algorithm to divide the simplified Directed Acyclic Graph into several parts for execution, and each part would be executed in one datacenter. However, these solutions only address bandwidth cost without carefully considering the job completion time.

As a representative work in the second category, Iridium~\cite{pu2015low} proposed an online heuristic to place both data and tasks across datacenters. Unfortunately, the model in Iridium is based on a few assumptions that are not realistic. First, they assume that sites are connected using a network with congestion-free core and the network bottlenecks only exist in the up/down links of sites. Second, their work can only be applied to simple 1- or 2-stage queries without distinguishing different dataset. Third, they assume that sites have relatively abundant compute and capacity and that I/O and CPU operations of tasks have zero duration.

Flutter~\cite{hu2016flutter} and Chen~\cite{chen2018scheduling} removed the assumption that network core is congestion-free and used a pair-wise connectivity model. What's more, rather than scheduling all the tasks together, Flutter~\cite{hu2016flutter} schedules ready tasks stage by stage in an online fasion. They formulated a lexicographical minimization problem of task assignment for a single stage of one job, and obtained its optimal solution. Chen~\cite{chen2018scheduling} take competition for resources among concurrent jobs into consideration. Using a similar theoretical foundation as~\cite{hu2016flutter}, they designed and implemented a new optimal scheduler to assign tasks across geo-datacenters, in order to better satisfy job requirements with max-min fairness achieved across their job completion times. 

Clarinet~\cite{viswanathan2016clarinet} is designed for SQL queries. They also abstract the WAN as a logical full mesh with fixed bandwidth links. It feeds the bandwidth information to the query plan optimizer to generate better query plans for queries over geo-distributed data. SWAG~\cite{hung2015scheduling} adjusts the order of jobs across data centers to reduce job completion times, which is orthogonal to my work.

None of existing work model task processing time and most of them only optimize data transfer time in their task placement algorithm. Nevertheless, task processing usually takes up a significant proportion of job completion time according to observations. And experiments show that the improvement of time efficiency is limited, if the task placement strategy doesn't take task processing time into consideration.
\begin{table}[htbp]
\centering
\caption{Summary of Related Work\iffalse Aimed at reducing job Completion Time\fi}
\label{related work}
\resizebox{\textwidth}{!} {
\begin{tabular}{|l|l|c|l|c|l|c|}
\hline
\shortstack{Works}     & \shortstack{Processing\\type}      & \shortstack{Data\\placement} & Task placement & \shortstack{Modeling\\processing\\time} & Connectivity & \shortstack{Multiple\\jobs} \\ \hline
Iridium \iffalse(SIGCOMM '15) \else ~\cite{pu2015low}\fi      & general & \checkmark & once per job   & -  & network core & - \\ \hline
Clarinet \iffalse(OSDI '16)\else ~\cite{viswanathan2016clarinet}\fi     & SQL                 & -   & once per job   & - & Pair-wise              & \checkmark    \\ \hline
Flutter \iffalse(TPDS '18)\else ~\cite{hu2016flutter}\fi      & general & -   & stage by stage & - & Pair-wise             & -    \\ \hline
Chen, et al. \iffalse(TNSE '18)\else ~\cite{chen2018scheduling}\fi  & general & - & stage by stage & - & Pair-wise             & \checkmark    \\ \hline
Our work          & general & - & stage by stage & \checkmark & Pair-wise  &             - \\ \hline
\end{tabular}
}
\end{table}

A comparison of algorithms aimed at time-efficient geo-distributed big-data processing based on several aspect such as data processing type, approach, task placement times and considerations is given in Table \ref{related work}.

In the past few years, performance modeling in MapReduce or Spark environments has also received much attention, and different approach~\cite{zhang2013performance,wang2015performance,wang2016modeling,nguyen2017understanding} were offered for predicting performance of MapReduce or Spark jobs. These works focus on MapReduce or Spark performance in a single cluster, while we focus on data processing jobs in a geo-distributed cluster.
\end{document}
